 import flwr as fl
from typing import Dict, List, Optional, Tuple
import torch
import torch.nn as nn
import random
import numpy as np
import copy
from collections import OrderedDict
from flwr.common import ndarrays_to_parameters, parameters_to_ndarrays
import matplotlib.pyplot as plt
import csv
import time
import os
from google.colab import files
import os
from google.colab import drive

########################################
# SEED
########################################
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed(SEED)
    torch.cuda.manual_seed_all(SEED)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

########################################
#history of clients
########################################
client_history = {}

########################################
# CSV Logging - Ensure File is Created at Start
########################################
csv_filename = "client_task_log.csv"
csv_path = os.path.join(os.getcwd(), csv_filename)  # Saves in the working directory

if not os.path.exists(csv_path):
    with open(csv_path, 'w', newline='') as file:
        writer = csv.writer(file)
########################################
# Machine Learning Model (Net)
########################################
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)
        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # Adjusted to match the output size
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))  # Output: (batch, 6, 12, 12)
        x = self.pool(torch.relu(self.conv2(x)))  # Output: (batch, 16, 4, 4)
        x = torch.flatten(x, 1)                  # Output: (batch, 16 * 4 * 4)
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = self.fc3(x)
        return x

########################################
# EdgeDevice Class
########################################
class EdgeDevice:
    def __init__(self, device_id, trainloader, valloader):
        self.device_id = device_id
        self.trainloader = trainloader
        self.valloader = valloader
        self.model = Net()  # Each device has its own local model

    def get_client(self):
        return FlowerClient(self.model, self.trainloader, self.valloader, self.device_id)

########################################
# EdgeServer Class
########################################
class EdgeServer:
    def __init__(self, server_id, devices: List[EdgeDevice]):
        self.server_id = server_id
        self.devices = devices
        self.model = Net()  # Each edge server has its own local model

    def aggregate(self):
        """Aggregate models from all connected devices."""
        total_samples = 0
        weighted_params = None

        for device in self.devices:
            client = device.get_client()
            parameters = client.get_parameters()
            num_samples = len(device.trainloader.dataset)

            if weighted_params is None:
                weighted_params = [num_samples * np.array(param) for param in parameters]
            else:
                for i, param in enumerate(parameters):
                    weighted_params[i] += num_samples * np.array(param)

            total_samples += num_samples

        # Average the parameters
        aggregated_params = [param / total_samples for param in weighted_params]
        return aggregated_params

########################################
# Parameter Utility Functions
########################################
def set_parameters(net: nn.Module, parameters: List[np.ndarray]):
    state_keys = list(net.state_dict().keys())
    state_dict = OrderedDict({k: torch.tensor(v, dtype=torch.float32) for k, v in zip(state_keys, parameters)})
    net.load_state_dict(state_dict, strict=True)

def get_parameters(net: nn.Module) -> List[np.ndarray]:
    return [val.cpu().numpy() for _, val in net.state_dict().items()]

def test(net, testloader):
    net.eval()
    correct, total = 0, 0
    criterion = nn.CrossEntropyLoss()
    total_loss = 0.0

    with torch.no_grad():
        for inputs, labels in testloader:
            inputs, labels = inputs.to(torch.device('cpu')), labels.to(torch.device('cpu'))
            outputs = net(inputs)
            total_loss += criterion(outputs, labels).item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    accuracy = 100.0 * correct / total
    avg_loss = total_loss / len(testloader)
    return avg_loss, accuracy

########################################
# Adjust L and H After Each Round
########################################
def adjust_task_assignment(client_id, success):
    """Adjust L, H, and task difficulty based on client execution ability."""
    global client_history

    if client_id not in client_history:
        print(f"⚠️ Warning: Client {client_id} missing from history. Initializing now.")
        client_history[client_id] = {"L": 50, "H": 100, "task": "Easy", "epochs": 50}

    history = client_history[client_id]

    # ✅ Extract values before modification
    before_L = history["L"]
    before_H = history["H"]
    before_task = history["task"]
    before_epochs = history["epochs"]

    if success:
        # ✅ If the client successfully completed H tasks, increase L and H
        history["L"] = before_L + 10
        history["H"] = before_H + 10
        history["task"] = "Difficult"
        history["epochs"] = history["L"]
    else:
        # ❌ If the client fails difficult tasks, halve both L and H
        history["L"] = max(10, before_L // 2)
        history["H"] = max(20, before_H // 2)
        history["task"] = "Easy"
        history["epochs"] = history["L"]

    return history["task"], history["epochs"], history["L"], history["H"]

########################################
# FlowerClient Class
########################################
class FlowerClient(fl.client.NumPyClient):

    def __init__(self, model, trainloader, testloader, cid):
        self.model = model
        self.trainloader = trainloader
        self.testloader = testloader
        self.cid = cid

    def get_parameters(self):
        return get_parameters(self.model)

    def set_parameters(self, parameters):
        set_parameters(self.model, parameters)

    def fit(self, parameters, config):
      """Train the model for a given number of epochs."""
      global client_history 
      self.set_parameters(parameters)
      self.model.train()
      optimizer = torch.optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)
      criterion = nn.CrossEntropyLoss()

      client_id = self.cid
      num_epochs = config.get("k1", 60)

      print(f"Client {client_id}: Training for {num_epochs} epochs.")

      start_time = time.time()

      for local_update in range(num_epochs):
          for inputs, labels in self.trainloader:
              inputs, labels = inputs.to(torch.device('cpu')), labels.to(torch.device('cpu'))
              optimizer.zero_grad()
              outputs = self.model(inputs)
              loss = criterion(outputs, labels)
              loss.backward()
              optimizer.step()

      end_time = time.time()
      training_time = end_time - start_time

      # ✅ Ensure client history exists before updating training_time
      if client_id not in client_history:
          client_history[client_id] = {"training_time": []}
      elif "training_time" not in client_history[client_id]:
          client_history[client_id]["training_time"] = []

      client_history[client_id]["training_time"].append(training_time)

      print(f"Client {client_id}: Training completed in {training_time:.2f} sec.")

      return self.get_parameters(), len(self.trainloader.dataset), {"training_time": training_time}


########################################
# Hierarchical Federated Learning with Flower
#######################################
def HierFL(args, trainloaders, valloaders, testloader):
    global client_history, global_model
    global_model = Net()
    global_weights = get_parameters(global_model)

    # Initialize Edge Devices
    edge_devices = [EdgeDevice(i, trainloaders[i], valloaders[i]) for i in range(args['NUM_DEVICES'])]
    num_edge_servers = args['NUM_EDGE_SERVERS']
    edge_servers = []
    devices_per_server = len(edge_devices) // num_edge_servers

    for i in range(num_edge_servers):
        start_idx = i * devices_per_server
        devices = edge_devices[start_idx:] if i == num_edge_servers - 1 else edge_devices[start_idx: start_idx + devices_per_server]
        edge_servers.append(EdgeServer(i, devices))

    # ✅ Ensure all clients are initialized
    for client_id in range(args['NUM_DEVICES']):
        if client_id not in client_history:
            client_history[client_id] = {
                "L": 50, "H": 70, "epochs": 50, "task": "Easy",
                "training_time": [], "accuracy": []
            }

    def evaluate_fn(server_round, parameters, config):
        set_parameters(global_model, parameters)
        loss, accuracy = test(global_model, testloader)
        return loss, {"accuracy": accuracy}

    # Define Strategy
    strategy = fl.server.strategy.FedAvg(
        fraction_fit=args['CLIENT_FRACTION'],
        fraction_evaluate=args['EVALUATE_FRACTION'],
        min_fit_clients=2,
        min_evaluate_clients=2,
        initial_parameters=ndarrays_to_parameters(global_weights),
        evaluate_fn=evaluate_fn,
    )

    for round_number in range(1, args['GLOBAL_ROUNDS'] + 1):
        print(f"\n🔵 Round {round_number}")

        # Select available clients
        available_clients = [cid for cid in range(args['NUM_DEVICES'])]
        if len(available_clients) < 2:
            print("⚠️ Not enough available clients. Skipping round.")
            continue

        selected_clients = random.sample(available_clients, min(2, len(available_clients)))
        print(f"🔹 Selected Clients: {selected_clients}")

        for client_id in selected_clients:
            client = FlowerClient(
                model=Net(),
                trainloader=trainloaders[client_id],
                testloader=testloader,
                cid=client_id,
            )

            history = client_history[client_id]
            before_L = history["L"]
            before_H = history["H"]
            before_task = history["task"]
            before_epochs = history["epochs"]

            # **Train Client with L-task**
            print(f"Client {client_id}: Assigned task {before_task} with {before_L} epochs.")
            _, _, train_metrics = client.fit(get_parameters(client.model), {"num_epochs": args["k1"]})
            training_time = train_metrics["training_time"]

            # ✅ Ensure training time is recorded in client history
            if "training_time" not in client_history[client_id]:
                client_history[client_id]["training_time"] = []
            client_history[client_id]["training_time"].append(training_time)

            success = True  # Assume success initially

            # **Check if Client Can Attempt H**
            if before_task == "Easy":
                print(f"Client {client_id}: Trying difficult task with {before_H} epochs.")
                _, _, train_metrics = client.fit(get_parameters(client.model), {"num_epochs": args["k1"]})
                training_time = train_metrics["training_time"]

                # Simulated failure condition
                if random.random() < 0.6:
                    success = False

            # **Update L and H Based on Success**
            if success:
                history["L"] += 10
                history["H"] += 10
                history["task"] = "Difficult"
            else:
                history["L"] = max(10, before_L // 2)
                history["H"] = max(20, before_H // 2)
                history["task"] = "Easy"

            history["epochs"] = history["L"]

            # ✅ **Move CSV Logging Inside the Loop**
            with open('client_task_log.csv', 'a', newline='') as file:
                writer = csv.writer(file)
                if os.stat("client_task_log.csv").st_size == 0:
                    writer.writerow(["Round", "Client ID", "Before Task", "Before Epochs", "Before L", "Before H",
                                     "After Task", "After Epochs", "After L", "After H"])
                writer.writerow([round_number, client_id, before_task, before_epochs, before_L, before_H,
                                 history["task"], history["epochs"], history["L"], history["H"]])

            print(f"Client {client_id}: Finished round with new L={history['L']}, H={history['H']}, Task={history['task']}")

        # 🔹 **Perform Edge Aggregation every k2 rounds**
        if round_number % args["k2"] == 0:
            print(f"🔹 Aggregating at EDGE SERVER (every {args['k2']} rounds)")
            for edge_server in edge_servers:
                aggregated_params = edge_server.aggregate()
                set_parameters(edge_server.model, aggregated_params)

        # 🌍 **Perform Global Aggregation every (k1 × k2) rounds**
        if round_number % (args["k1"] * args["k2"]) == 0:
            print(f"🌍 Aggregating at GLOBAL SERVER (every {args['k1'] * args['k2']} rounds)")
            global_weights = get_parameters(global_model)
            set_parameters(global_model, global_weights)

    print("✅ Federated Training Complete!")




########################################
# Main
#######################################

def main():
    from torchvision import datasets, transforms
    from torch.utils.data import DataLoader

    def load_datasets(num_clients: int, batch_size: int = 32):
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # Convert grayscale to 3 channels
            transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]
        ])
        train_dataset = datasets.MNIST(".", train=True, download=True, transform=transform)
        test_dataset = datasets.MNIST(".", train=False, download=True, transform=transform)

        indices = torch.randperm(len(train_dataset), generator=torch.Generator().manual_seed(SEED))
        split = []
        num_classes = 10
        samples_per_client = len(train_dataset) // num_clients

        # Extract labels from dataset
        labels = np.array(train_dataset.targets)

        for i in range(num_clients):
            class_indices = np.where((labels == (i % num_classes)) | (labels == ((i+1) % num_classes)))[0]
            selected_indices = np.random.choice(class_indices, samples_per_client, replace=False)
            split.append(torch.tensor(selected_indices))

        trainloaders = [DataLoader(torch.utils.data.Subset(train_dataset, s), batch_size=batch_size, shuffle=True, generator=torch.Generator().manual_seed(SEED)) for s in split]
        valloaders = [DataLoader(torch.utils.data.Subset(train_dataset, s), batch_size=batch_size, shuffle=False) for s in split]
        testloader = DataLoader(test_dataset, batch_size=batch_size)
        return trainloaders, valloaders, testloader

    args = {
        'NUM_DEVICES': 5,
        'NUM_EDGE_SERVERS': 5,
        'GLOBAL_ROUNDS':3,
        'LEARNING_RATE': 0.001,
        'DEVICE': torch.device("cuda" if torch.cuda.is_available() else "cpu"),
        'CLIENT_FRACTION': 0.2,
        'EVALUATE_FRACTION': 0.2,
        'k1': 60,  # Local updates parameter
        'k2': 1  # Edge-to-cloud aggregation frequency
    }

    trainloaders, valloaders, testloader = load_datasets(args['NUM_DEVICES'])
    HierFL(args, trainloaders, valloaders, testloader)

if __name__ == "__main__":
    main()


